{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7c2bcb8-694c-4ef3-882a-12d8ec1110b6",
   "metadata": {},
   "source": [
    "## Simpel tokenizers\n",
    "\n",
    "Der findes en lang række eksisterende tokenizers fra forskellige pakker i Python. Disse kan med fordel bruges frem for at skrive sin egen tokenizer fra bunden.\n",
    "\n",
    "SpaCy's sprogmodeller indeholder altid en tokenizer. Hvis man blot vil bruge selve tokenizeren uden de andre \"processors\" i modellen, kan man gøre det lig nedenstående:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1745b686-f3f2-459f-9ab0-07b40543b4a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T07:49:37.465980Z",
     "iopub.status.busy": "2022-10-21T07:49:37.465199Z",
     "iopub.status.idle": "2022-10-21T07:49:38.530474Z",
     "shell.execute_reply": "2022-10-21T07:49:38.529491Z",
     "shell.execute_reply.started": "2022-10-21T07:49:37.465927Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Politiet, har, givet, borgerne, råd]\n"
     ]
    }
   ],
   "source": [
    "import spacy # importer pakke\n",
    "\n",
    "nlp = spacy.load('da_core_news_sm') # indlæs sprogmodel\n",
    "\n",
    "tokenizer = nlp.tokenizer # hiv tokenizer ud af model (funktion for sig)\n",
    "\n",
    "text = 'Politiet har givet borgerne råd' # tekststykke\n",
    "tokens = list(tokenizer(text)) # brug tokenizer - her liste af tokens\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07df6ed7-de7e-44b3-8dc0-03839d8afddf",
   "metadata": {},
   "source": [
    "## Udvidet tokenizer\n",
    "\n",
    "Man kan med fordel udnytte de forskellige måder, som spaCy's sprogmodeller behandler og analyserer tekst. \n",
    "\n",
    "I nedenstående defineres en udvidet tokenizerfunktion. Bemærk, hvordan de enkelte elementer af funktionen kan rettes til (hvilke stopord, hvilke part-of-speech tags, token længe, hvorvidt der skal bruges lemma eller ej)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36b497d7-72bb-4774-bb6c-47ffcf90acc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T07:51:53.194419Z",
     "iopub.status.busy": "2022-10-21T07:51:53.193799Z",
     "iopub.status.idle": "2022-10-21T07:51:53.214502Z",
     "shell.execute_reply": "2022-10-21T07:51:53.213475Z",
     "shell.execute_reply.started": "2022-10-21T07:51:53.194386Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['politi', 'give', 'borger', 'råd']\n"
     ]
    }
   ],
   "source": [
    "def tokenizer(text):\n",
    "    \n",
    "    custom_stops = [\"\"] # Definerer kontekstspecifikke stopord\n",
    "    default_stopwords = list(nlp.Defaults.stop_words) # Indlæser prædefineret stopordsliste\n",
    "    stop_words = default_stopwords + custom_stops # Danner samlet stopordsliste\n",
    "    \n",
    "    pos_tags = ['PROPN', 'ADJ', 'NOUN', 'VERB'] # Definerer POS-tags som skal bevares\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    tokens = []\n",
    "\n",
    "    for word in doc: # Looper igennem hvert ord i tweet\n",
    "        if (len(word.lemma_) < 3): # Ord må ikke være mindre end 3 karakterer - går videre til næste ord, hvis det er\n",
    "            continue\n",
    "        if (word.pos_ in pos_tags) and (word.lemma_ not in stop_words): # Tjek at ordets POS-tag indgår i listen af accepterede tags og at ordet ikke er stopord\n",
    "            tokens.append(word.lemma_) # Tilføj ordets lemma til tokens, hvis if-betingelse er opfyldt\n",
    "                \n",
    "    return(tokens)\n",
    "\n",
    "text = 'Politiet har givet borgerne råd' # tekststykke\n",
    "tokens = tokenizer(text) # brug tokenizer - her liste af tokens\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0424f9f2-c770-452b-aa3f-bfe0140be6fa",
   "metadata": {},
   "source": [
    "## Vectorizers\n",
    "\n",
    "`sklearn` indeholder forskellige \"text-vectorization\"-funktioner; altså funktioner, der omdanner tekststykker til matematiske repræsentationer.\n",
    "\n",
    "`CountVectorizer()` laver simple ordtællinger. Vectorizers fra `sklearn` bruges typisk på følgende måde:\n",
    "\n",
    "1. Definér vectorizerfunktion (hvad skal funktionen, hvilke parametre)\n",
    "2. Brug/\"fit\" funktionen på tekster/corpus (gerne som liste af strings)\n",
    "3. Konvertér til passende datastruktur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d3ccbfd-aa23-4050-a707-9b76c2c372c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T07:56:02.657923Z",
     "iopub.status.busy": "2022-10-21T07:56:02.657275Z",
     "iopub.status.idle": "2022-10-21T07:56:02.665131Z",
     "shell.execute_reply": "2022-10-21T07:56:02.663714Z",
     "shell.execute_reply.started": "2022-10-21T07:56:02.657870Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = ['Vi er utroligt beærede',\n",
    "         'Vi vil gerne dele prisen med alle',\n",
    "         'Det skal vi have gjort op med.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3123818-32f7-420b-a4ef-726e02b5ad31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T07:56:02.790110Z",
     "iopub.status.busy": "2022-10-21T07:56:02.789320Z",
     "iopub.status.idle": "2022-10-21T07:56:02.810932Z",
     "shell.execute_reply": "2022-10-21T07:56:02.810143Z",
     "shell.execute_reply.started": "2022-10-21T07:56:02.790040Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alle</th>\n",
       "      <th>beærede</th>\n",
       "      <th>dele</th>\n",
       "      <th>det</th>\n",
       "      <th>er</th>\n",
       "      <th>gerne</th>\n",
       "      <th>gjort</th>\n",
       "      <th>have</th>\n",
       "      <th>med</th>\n",
       "      <th>op</th>\n",
       "      <th>prisen</th>\n",
       "      <th>skal</th>\n",
       "      <th>utroligt</th>\n",
       "      <th>vi</th>\n",
       "      <th>vil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alle  beærede  dele  det  er  gerne  gjort  have  med  op  prisen  skal  \\\n",
       "0     0        1     0    0   1      0      0     0    0   0       0     0   \n",
       "1     1        0     1    0   0      1      0     0    1   0       1     0   \n",
       "2     0        0     0    1   0      0      1     1    1   1       0     1   \n",
       "\n",
       "   utroligt  vi  vil  \n",
       "0         1   1    0  \n",
       "1         0   1    1  \n",
       "2         0   1    0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer # importer CountVectorizer funktion\n",
    "\n",
    "vectorizer = CountVectorizer() # dan vectorizerfunktion\n",
    "transformed_documents = vectorizer.fit_transform(texts) # brug vectorizer på tekster\n",
    "\n",
    "transformed_documents_as_array = transformed_documents.toarray()# Konverter fittet vectorizer til array\n",
    "\n",
    "count_df = pd.DataFrame(transformed_documents_as_array, columns = vectorizer.get_feature_names_out()) # Konverter til data frame\n",
    "\n",
    "count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02efe034-e045-45a6-a9ab-9c0885691450",
   "metadata": {},
   "source": [
    "### TfidfVectorizer\n",
    "\n",
    "`sklearn` har også en tf-idf vectorizer. Denne laver tf-idf vægtning af ord i teksten. \n",
    "\n",
    "*Bemærk:* Som standard normaliserer funktionen vægtene (kvadratsummen af vægte for hver tekst = 1 - se evt.: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d90e4552-b58f-4ec6-93c7-24495cd7bd9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-18T12:56:33.680311Z",
     "iopub.status.busy": "2022-10-18T12:56:33.680050Z",
     "iopub.status.idle": "2022-10-18T12:56:33.697354Z",
     "shell.execute_reply": "2022-10-18T12:56:33.696601Z",
     "shell.execute_reply.started": "2022-10-18T12:56:33.680289Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alle</th>\n",
       "      <th>beærede</th>\n",
       "      <th>dele</th>\n",
       "      <th>det</th>\n",
       "      <th>er</th>\n",
       "      <th>gerne</th>\n",
       "      <th>gjort</th>\n",
       "      <th>have</th>\n",
       "      <th>med</th>\n",
       "      <th>op</th>\n",
       "      <th>prisen</th>\n",
       "      <th>skal</th>\n",
       "      <th>utroligt</th>\n",
       "      <th>vi</th>\n",
       "      <th>vil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.546454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.546454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.546454</td>\n",
       "      <td>0.322745</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.410747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.312384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242594</td>\n",
       "      <td>0.410747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410747</td>\n",
       "      <td>0.410747</td>\n",
       "      <td>0.312384</td>\n",
       "      <td>0.410747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242594</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       alle   beærede      dele       det        er     gerne     gjort  \\\n",
       "0  0.000000  0.546454  0.000000  0.000000  0.546454  0.000000  0.000000   \n",
       "1  0.410747  0.000000  0.410747  0.000000  0.000000  0.410747  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.410747  0.000000  0.000000  0.410747   \n",
       "\n",
       "       have       med        op    prisen      skal  utroligt        vi  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.546454  0.322745   \n",
       "1  0.000000  0.312384  0.000000  0.410747  0.000000  0.000000  0.242594   \n",
       "2  0.410747  0.312384  0.410747  0.000000  0.410747  0.000000  0.242594   \n",
       "\n",
       "        vil  \n",
       "0  0.000000  \n",
       "1  0.410747  \n",
       "2  0.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer() # dan vectorizerfunktion\n",
    "transformed_documents = vectorizer.fit_transform(texts) # brug vectorizer på tekster\n",
    "\n",
    "# Konverter fittet vectorizer til array\n",
    "transformed_documents_as_array = transformed_documents.toarray()\n",
    "\n",
    "# Konverter til data frame\n",
    "tfidf_df = pd.DataFrame(transformed_documents_as_array, columns = vectorizer.get_feature_names_out())\n",
    "\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfed577-b647-414e-8eb4-c608ebca5f18",
   "metadata": {},
   "source": [
    "### Tilpasning af vectorizer - egen tokenizer\n",
    "\n",
    "Vectorizer-funktionerne fra `sklearn` kan tilpasses på en lang række forskellige måder. En måde, som man kan tilpasse funktionerne på, er ved at bruge sin egen tokenizer. \n",
    "\n",
    "For at gøre dette, skal man blot have defineret en funktion, der omdanner et enkelt tekststykke til tokens (lig funktionen defineret tidligere i denne notebook). Denne sættes så ind som tokenizer, når man danner vectorizerfunktionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4767832-4c67-48b0-b0a7-887d99a65d91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T08:00:33.029838Z",
     "iopub.status.busy": "2022-10-21T08:00:33.028944Z",
     "iopub.status.idle": "2022-10-21T08:00:33.067726Z",
     "shell.execute_reply": "2022-10-21T08:00:33.066844Z",
     "shell.execute_reply.started": "2022-10-21T08:00:33.029782Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beære</th>\n",
       "      <th>dele</th>\n",
       "      <th>pris</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beære      dele      pris\n",
       "0    1.0  0.000000  0.000000\n",
       "1    0.0  0.707107  0.707107\n",
       "2    0.0  0.000000  0.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer = tokenizer) # dan vectorizerfunktion med egen tokenizer\n",
    "transformed_documents = vectorizer.fit_transform(texts) # brug vectorizer på tekster\n",
    "\n",
    "# Konverter fittet vectorizer til array\n",
    "transformed_documents_as_array = transformed_documents.toarray()\n",
    "\n",
    "# Konverter til data frame\n",
    "tfidf_df = pd.DataFrame(transformed_documents_as_array, columns = vectorizer.get_feature_names_out())\n",
    "\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fd31ef-72cc-4c98-b0fc-d23fa6358746",
   "metadata": {},
   "source": [
    "### Tilpasning af vectorizer - dokumentgrænser\n",
    "\n",
    "En anden måde, som man kan tilpasse vectorizers, er ved at sætte minimum- og maksimumsgrænser for, hvor mange dokumenter, som ord skal indgå i.\n",
    "\n",
    "Argumenterne `min_df` og `max_df` bruges til at sætte grænser for hhv. minimum antal dokumenter og maksimum antal dokumenter, som ord skal indgå i (df = \"document frequency\"). Ved begge kan man både angive absolutte tal eller andel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e702818-9142-4aba-83fb-b8976422c00e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T08:03:01.268510Z",
     "iopub.status.busy": "2022-10-21T08:03:01.267834Z",
     "iopub.status.idle": "2022-10-21T08:03:01.287533Z",
     "shell.execute_reply": "2022-10-21T08:03:01.286505Z",
     "shell.execute_reply.started": "2022-10-21T08:03:01.268454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>med</th>\n",
       "      <th>vi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.789807</td>\n",
       "      <td>0.613356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.789807</td>\n",
       "      <td>0.613356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        med        vi\n",
       "0  0.000000  1.000000\n",
       "1  0.789807  0.613356\n",
       "2  0.789807  0.613356"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 2) # dan vectorizerfunktion med egen tokenizer - ord skal indgå i to dokumenter\n",
    "transformed_documents = vectorizer.fit_transform(texts) # brug vectorizer på tekster\n",
    "\n",
    "# Konverter fittet vectorizer til array\n",
    "transformed_documents_as_array = transformed_documents.toarray()\n",
    "\n",
    "# Konverter til data frame\n",
    "tfidf_df = pd.DataFrame(transformed_documents_as_array, columns = vectorizer.get_feature_names_out())\n",
    "\n",
    "tfidf_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
